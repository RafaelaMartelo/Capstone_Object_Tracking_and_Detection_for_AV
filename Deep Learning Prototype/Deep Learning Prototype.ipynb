{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6da769a",
   "metadata": {},
   "source": [
    "## Prototype\n",
    "#### *(Still in Progress)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffab6cb",
   "metadata": {},
   "source": [
    "## 1. Introduction to Dataset and Augmentation Strategy\n",
    "\n",
    "In the development of our object detection prototype, we have meticulously prepared our dataset and applied strategic augmentations to optimize model training and performance. Utilizing **Roboflow**, a powerful tool for image augmentation and preprocessing, we enhanced our initial dataset of 198 images. The augmentation process introduced variations in blur and noise, specifically:\n",
    "\n",
    "- **Blur**: Applied up to 1.7px, adding realistic variations to the images.\n",
    "- **Noise**: Incorporated up to 0.3% of pixels, introducing visual imperfections to challenge the model's detection capabilities.\n",
    "\n",
    "### Augmented Dataset Overview\n",
    "\n",
    "After augmentation, our dataset distribution for model training, validation, and testing is as follows:\n",
    "\n",
    "- **Training Set**: Expanded to 278 images, providing a broad base for model learning.\n",
    "- **Validation Set**: Consists of 39 images, used for fine-tuning model parameters.\n",
    "- **Test Set**: Contains 20 images, reserved for final model evaluation.\n",
    "\n",
    "### Label Distribution in the Dataset\n",
    "\n",
    "The augmented dataset encompasses a total of 1,590 labels, distributed across three categories:\n",
    "\n",
    "- **Cars**: 1,178 labels, the majority of our dataset, focusing on vehicular detection.\n",
    "- **Trucks**: 134 labels, introducing larger vehicle detection challenges.\n",
    "- **Persons**: 278 labels, essential for scenarios where human presence is relevant.\n",
    "\n",
    "### Towards Prototype Construction\n",
    "\n",
    "With our dataset prepared and augmented, we're eager to explore fine-tuning strategies to enhance our model's accuracy and reliability. These strategies are pivotal in constructing a robust prototype for our object detection project, aiming to refine our model's performance to effectively recognize and classify objects under diverse conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513ebcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.225, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in object_detect_proto-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12511/12511 [00:02<00:00, 4227.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to object_detect_proto-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686/686 [00:00<00:00, 826.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"IvxuC5AtkVBPx3o8pcGV\")\n",
    "project = rf.workspace(\"machine-learning-engineer-bootcamp\").project(\"object_detect_proto\")\n",
    "dataset = project.version(2).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbccd9a",
   "metadata": {},
   "source": [
    "## 1.2. Object Detection with YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11245cd",
   "metadata": {},
   "source": [
    "YOLOv8 detection models yolov8n.pt and are pretrained on the COCO detection dataset with an image resolution of 640. \n",
    "\n",
    "The COCO dataset has the classes:\n",
    "\n",
    "    -person, bicycle, car, motorbike, aeroplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, sofa, pottedplant, bed, diningtable, toilet, tvmonitor, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush\n",
    "    \n",
    "As stated above we have renamed the 'pedestrian' class to 'person', since the pretrained model wouldn't recognize that class otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88696af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "Setup complete âœ… (4 CPUs, 15.8 GB RAM, 234.3/953.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# !pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a7c98",
   "metadata": {},
   "source": [
    "### Leraning Rate Scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed607d34",
   "metadata": {},
   "source": [
    "## 8T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8f7f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.11 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=50, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train8\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136761 parameters, 11136745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\rafae\\Documents\\Capstone\\object_detect_proto-2\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\rafae\\Documents\\Capstone\\object_detect_proto-2\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train8\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.272      0.412       0.23       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.273      0.388      0.307      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.395      0.493      0.364      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.347      0.489      0.404      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.256      0.341      0.283      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.381      0.483      0.415      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.578      0.527      0.564       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.578      0.568      0.599      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.627       0.55      0.618      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.599      0.544      0.596      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.662      0.552      0.618      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.641      0.572      0.606      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.797      0.544      0.641      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.724      0.592      0.666      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.808      0.522      0.654      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.79      0.532      0.699      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.698       0.64      0.726      0.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.822      0.609      0.718      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.812      0.617      0.717      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.837      0.585      0.722      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.847      0.609      0.742      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.856      0.591      0.753      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.78      0.679       0.76      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.738      0.678      0.761      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.803      0.688      0.773       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.825      0.689      0.771      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.856      0.647      0.771      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.811      0.673      0.773       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.797      0.709      0.774       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.852      0.673      0.777        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.764      0.684       0.77      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.785      0.685      0.783      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.837      0.694      0.794      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.889      0.663      0.804      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.832      0.711      0.802      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.889       0.68        0.8       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.879      0.671      0.798      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.883      0.678      0.806       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.852      0.711      0.808      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290        0.8      0.717      0.794      0.544\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.806      0.693      0.793      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.844      0.708      0.807      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.88      0.694      0.819      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.888      0.688      0.818      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.891      0.688      0.816      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.881       0.69      0.816      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.882      0.698      0.818      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.883      0.694      0.816      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.877      0.695      0.815      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.872      0.695      0.815      0.559\n",
      "\n",
      "50 epochs completed in 9.235 hours.\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\train8\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all         39        290      0.872      0.695      0.815      0.559\n",
      "                   car         39        221      0.906      0.692      0.851      0.598\n",
      "                person         39         48      0.804      0.583      0.713      0.382\n",
      "                 truck         39         21      0.905       0.81      0.882      0.697\n",
      "Speed: 7.4ms preprocess, 860.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%capture captured_output\n",
    "# Code that produces output\n",
    "\n",
    "model_1 = YOLO('yolov8s.pt')  # load a pretrained model \n",
    "# Train the model\n",
    "results = model_1.train(data='data.yaml', epochs=50, imgsz=640, batch= 8, cos_lr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01de85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\rafae\\Documents\\Capstone\\object_detect_proto-2\\valid\\labels.cache... 39 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39        290      0.872      0.695      0.815      0.559\n",
      "                   car         39        221      0.906      0.692      0.851      0.598\n",
      "                person         39         48      0.804      0.583      0.713      0.382\n",
      "                 truck         39         21      0.905       0.81      0.882      0.697\n",
      "Speed: 6.6ms preprocess, 779.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train82\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.59774,     0.38205,      0.6966])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model_1.val()\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe599b",
   "metadata": {},
   "source": [
    "## 8F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb3068b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.11 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=50, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train9\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136761 parameters, 11136745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train9', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Plotting labels to runs\\detect\\train9\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train9\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.272      0.412       0.23       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.359      0.292      0.293      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.597      0.348      0.344      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.677      0.406      0.462      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.433      0.476      0.485      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.423      0.593      0.492      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.597      0.444      0.495      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.67      0.597      0.633      0.325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.707      0.576      0.653      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.634        0.5      0.588      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.728      0.555      0.631      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.702      0.514      0.658      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.804      0.555      0.691      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.72      0.508      0.649      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.758      0.649      0.724      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.784      0.633      0.722      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.766      0.611      0.718      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.691      0.624      0.695      0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.772      0.597      0.718       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.821      0.609      0.732      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.857      0.615      0.754      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.762       0.68      0.748      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.816      0.654      0.778      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.751      0.643      0.752      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.774       0.66      0.762      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.803      0.651      0.762      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.836      0.658      0.775      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.81      0.691      0.786      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.885      0.638      0.791      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.859       0.66      0.797       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.844      0.668       0.79      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.833      0.691      0.805      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.783      0.752      0.806      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.778      0.738       0.81      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.822      0.712      0.798      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.783      0.752      0.801      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.778      0.723      0.802      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.851      0.617      0.785      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.82      0.737      0.792       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.858      0.677      0.793      0.523\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.872      0.666      0.795      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.863      0.697      0.811      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.885      0.687      0.809      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.868      0.678        0.8      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.777      0.755      0.818      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.849      0.695      0.817      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.825      0.708      0.806       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.826      0.704      0.801      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.812      0.707      0.804      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.824      0.705       0.81      0.565\n",
      "\n",
      "50 epochs completed in 9.403 hours.\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\train9\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all         39        290      0.824      0.705       0.81      0.565\n",
      "                   car         39        221      0.881      0.702      0.861      0.616\n",
      "                person         39         48      0.751      0.604      0.708      0.398\n",
      "                 truck         39         21      0.841       0.81      0.862       0.68\n",
      "Speed: 8.1ms preprocess, 1045.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%capture captured_output\n",
    "# Code that produces output\n",
    "\n",
    "model_2 = YOLO('yolov8s.pt')  # load a pretrained model \n",
    "# Train the model\n",
    "results = model_2.train(data='data.yaml', epochs=50, imgsz=640, batch= 8, cos_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df43158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\rafae\\Documents\\Capstone\\object_detect_proto-2\\valid\\labels.cache... 39 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:38<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39        290      0.824      0.705       0.81      0.565\n",
      "                   car         39        221      0.881      0.702      0.861      0.616\n",
      "                person         39         48      0.751      0.604      0.708      0.398\n",
      "                 truck         39         21      0.841       0.81      0.862       0.68\n",
      "Speed: 7.6ms preprocess, 936.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train92\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0.6163,     0.39814,      0.6801])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model_2.val()\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e882d8e",
   "metadata": {},
   "source": [
    "## 16T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b30778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.11 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.11.4 torch-2.1.1+cpu CPU (Intel Core(TM) i7-7600U 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train10\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136761 parameters, 11136745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Plotting labels to runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290       0.37      0.296      0.265      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.668      0.303      0.387      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.561      0.402      0.442      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.533      0.284      0.336      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.474      0.385      0.391      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.653      0.365      0.462      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.542      0.472      0.454      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.652       0.53      0.602      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.657      0.563       0.63      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.797      0.537       0.63      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.729      0.542      0.626      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.721      0.576      0.647      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.762       0.57      0.661      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.686      0.519      0.615      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.742      0.593      0.718      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.877      0.587      0.683      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.856      0.606       0.71       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.889      0.594      0.751      0.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.836      0.634      0.746      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.839      0.598      0.746      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.816      0.633       0.75      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.787      0.672      0.756       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.842      0.648      0.779      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.846      0.672      0.791      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.782       0.67      0.761      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         39        290      0.827      0.682      0.768      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    }
   ],
   "source": [
    "%%capture captured_output\n",
    "# Code that produces output\n",
    "\n",
    "model_3 = YOLO('yolov8s.pt')  # load a pretrained model \n",
    "# Train the model\n",
    "results = model_3.train(data='data.yaml', epochs=50, imgsz=640, batch= 16, cos_lr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e48ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model_3.val()\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315742c",
   "metadata": {},
   "source": [
    "## 16F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e086dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Code that produces output\n",
    "\n",
    "model_4 = YOLO('yolov8s.pt')  # load a pretrained model \n",
    "# Train the model\n",
    "results = model_4.train(data='data.yaml', epochs=50, imgsz=640, batch= 16, cos_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b770d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model_4.val()\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75830019",
   "metadata": {},
   "source": [
    "**Evaluation Metrics:**\n",
    "\n",
    "**Images:** Total number of images in the evaluation set.\n",
    "\n",
    "**Instances:** Total number of instances (objects) across all images.\n",
    "\n",
    "**Box(P):** Precision of the bounding boxes. It's showing 0 in this case.\n",
    "\n",
    "**R:** Recall, indicating the fraction of relevant instances that have been retrieved over the total amount of relevant instances. It's showing 0 in this case.\n",
    "\n",
    "**mAP50:** Mean Average Precision at an IoU (Intersection over Union) threshold of 0.5. It's showing 0, which means that at this IoU threshold, the model did not achieve any average precision.\n",
    "\n",
    "**mAP50-95:** Mean Average Precision over the IoU range from 0.5 to 0.95. It's showing 0 as well.\n",
    "\n",
    "In summary, the output is suggesting that, for the specified class (\"all\"), the model's performance in terms of precision, recall, and average precision is currently reported as 0. This might indicate that the model is not performing well on the specified class based on the evaluation metrics used. Improving these metrics would typically involve further model training, tuning, or adjusting parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e545dab",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209bfe8",
   "metadata": {},
   "source": [
    "Visual Object Dataset converter\n",
    "\n",
    "Convert from data in KITTI format to Pascal VOC format:\n",
    "\n",
    "$ python3.6 vod_converter/main.py --from kitti --from-path datasets/mydata-kitti --to voc --to-path datasets/mydata-voc\n",
    "\n",
    "https://github.com/umautobots/vod-converter/blob/master/vod_converter/voc.py\n",
    "\n",
    "YOLO resources:\n",
    "\n",
    "https://medium.com/@beyzaakyildiz/what-is-yolov8-how-to-use-it-b3807d13c5ce\n",
    "https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\n",
    "\n",
    "Faster RCNN resources:\n",
    "\n",
    "https://medium.com/@fractal.ai/guide-to-build-faster-rcnn-in-pytorch-42d47cb0ecd3\n",
    "\n",
    "-https://github.com/chenyuntc/simple-faster-rcnn-pytorch/blob/master/model/faster_rcnn_vgg16.py\n",
    "    \n",
    "Faster RCNN pretrained on COCO dataset: https://github.com/trian-ctrn/IntrotoCS_2023/blob/master/Faster_RCNN/IntroToCS_Faster_RCNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1b24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
